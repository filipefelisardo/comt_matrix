import numpy as np
import pandas as pd
import random
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score

class Perceptron():
    #initialize hyperparameters (learning rate and number of iterations)
    def __init__(self, eta=0.1, n_iter=50, nameA='', nameB=''):
        self.eta = eta
        self.n_iter = n_iter
        self.nameA = nameA
        self.nameB = nameB

    def step_fit(self, X, y):
        #iterate over labelled dataset updating weights for each features accordingly (stochastic gradient descent)
        for xi, label in zip(X, y):
            update = self.eta * (label-self.predict(xi))
            self.w_[1:] += update * xi
            self.w_[0] += update
        return self

    #compute the net input i.e scalar sum of X and the weights plus the bias value
    def net_input(self, X):
        return np.dot(X, self.w_[1:]) + self.w_[0]

    #predict a classification for a sample of features X
    def predict(self, X):
        return np.where(self.net_input(X) >= 0.0, 1, -1)

    def init_plot(self):
        self.line.set_data([],[])
        return self.line,

    def animate(self, iteration_number, X, y):
        self.step_fit(X, y)
        x, y = self.plot_line(X)
        self.line.set_data(x, y)
        if iteration_number%2==0:
            self.ax.text(max(X[:,0])-0.5, min(X[:,1])+0.5, f'Iteration: {iteration_number}', fontsize=12)  # Update iteration number
        else:
            self.ax.text(max(X[:,0])-0.5, min(X[:,1])+0.5, 'Iteration:'+' '*8, fontsize=12, bbox=dict(facecolor='white', alpha=1))
        return self.line,

    def plot_line(self, X):
        x = []
        y = []
        slope = -(self.w_[0]/self.w_[2])/(self.w_[0]/self.w_[1])
        intercept = -self.w_[0]/self.w_[2]
        for i in np.linspace(np.amin(X[:,0])-0.5,np.amax(X[:,0])+0.5):
            #y=mx+c, m is slope and c is intercept
            x.append(i)
            y.append((slope*i) + intercept)

        return x, y

    def animated_fit(self, X, y):
        self.w_ = [random.uniform(-1.0, 1.0) for _ in range(1+X.shape[1])] #randomly initialize weights

        #here figure must be defined as a variable so it can be passed to FuncAnimation
        self.fig = plt.figure()

        #setting x and y limits with a 0.5 offset
        self.ax = plt.axes(xlim=(min(X[:,0])-0.5, max(X[:,0])+0.5), ylim=(min(X[:,1])-0.5, max(X[:,1])+0.5))

        #plotting our training points
        self.ax.plot(X[0:50, 0],X[0:50, 1], "bo", label=self.nameA)
        self.ax.plot(X[50:100, 0],X[50:100, 1], "rx", label=self.nameB)

        #labelling
        self.ax.legend(loc='upper left')

        #initialization of separation line and our animation object
        self.line, = self.ax.plot([], [], lw=2)
        anim = FuncAnimation(self.fig, self.animate, init_func=self.init_plot, fargs=(X, y,), frames=self.n_iter, interval=200, blit=True)
        anim.save('learning_process.gif', writer='imagemagick')

    def validate(self, X_val, y_val):
        y_pred = self.predict(X_val)
        cm = confusion_matrix(y_val, y_pred)
        accuracy = accuracy_score(y_val, y_pred)
        precision = precision_score(y_val, y_pred)
        recall = recall_score(y_val, y_pred)
        f1 = f1_score(y_val, y_pred)
        return cm, accuracy, precision, recall, f1

# import dataset
df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)

SPECIES_1 = {'name':"Iris-setosa", 's':0, 'end':50} #0:50 # small size
SPECIES_2 = {'name':"Iris-versicolor", 's':50, 'end':100} # 50:100
SPECIES_3 = {'name':"Iris-virginica", 's':100, 'end':150} # 100:150
spA, spB = SPECIES_2, SPECIES_3

# preparing our data to be understood by our model
X = df.iloc[np.r_[spA['s']:spA['end'], spB['s']:spB['end']], [0,2]].values
y = df.iloc[np.r_[spA['s']:spA['end'], spB['s']:spB['end']], 4].values
# y = np.where(y == 'Iris-setosa', -1, 1)
y = np.where(y == spB['name'], -1, 1)

# Shuffle the data
indices = np.arange(X.shape[0])
np.random.shuffle(indices)
X = X[indices]
y = y[indices]

# Splitting the dataset into training and validation sets (80% training, 20% validation)
split = int(0.8 * len(X))
X_train, X_val = X[:split], X[split:]
y_train, y_val = y[:split], y[split:]

ppn = Perceptron(eta=0.1, n_iter=150, nameA=spA['name'], nameB=spB['name']) # initializing a new perceptron
ppn.animated_fit(X_train, y_train)

# Validation
cm, accuracy, precision, recall, f1 = ppn.validate(X_val, y_val)
print("Confusion Matrix:")
print(cm)
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

# Plot confusion matrix
plt.figure()
plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.colorbar()
tick_marks = np.arange(len(classes))
plt.xticks(tick_marks, classes, rotation=45)
plt.yticks(tick_marks, classes)
plt.xlabel('Predicted label')
plt.ylabel('True label')
thresh = cm.max() / 2.
for i, j in np.ndindex(cm.shape):
    plt.text(j, i, format(cm[i, j], 'd'),
             horizontalalignment='center',
             color='white' if cm[i, j] > thresh else 'black')
plt.tight_layout()
plt.savefig('confusion_matrix.png')
plt.show()

